{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Latent Risk Factor - Pipeline Dashboard\n",
    "\n",
    "Central configuration and execution notebook for the full walk-forward validation pipeline.\n",
    "\n",
    "**Workflow:**\n",
    "1. Configure all parameters (Sections 1-2)\n",
    "2. Load data (Section 3)\n",
    "3. Run pipeline (Section 4)\n",
    "4. Inspect results (Sections 5-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import tempfile\n",
    "from dataclasses import replace, asdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Project root: go up from notebooks/ to project root\n",
    "_NB_DIR = Path(os.path.abspath(\"\")).resolve()\n",
    "PROJECT_ROOT = (_NB_DIR / \"..\").resolve() if _NB_DIR.name == \"notebooks\" else _NB_DIR\n",
    "os.chdir(PROJECT_ROOT)\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.config import (\n",
    "    PipelineConfig,\n",
    "    DataPipelineConfig,\n",
    "    VAEArchitectureConfig,\n",
    "    LossConfig,\n",
    "    TrainingConfig,\n",
    "    InferenceConfig,\n",
    "    RiskModelConfig,\n",
    "    PortfolioConfig,\n",
    "    WalkForwardConfig,\n",
    ")\n",
    "from src.data_pipeline.data_loader import generate_synthetic_csv, load_stock_data\n",
    "from src.data_pipeline.returns import compute_log_returns\n",
    "from src.data_pipeline.features import compute_trailing_volatility\n",
    "from src.integration.pipeline import FullPipeline\n",
    "from src.integration.reporting import format_summary_table, serialize_for_json\n",
    "from src.integration.visualization import (\n",
    "    plot_fold_metrics,\n",
    "    plot_e_star_distribution,\n",
    "    plot_pairwise_heatmap,\n",
    "    style_summary_table,\n",
    "    style_fold_table,\n",
    ")\n",
    "from src.walk_forward.selection import aggregate_fold_metrics, summary_statistics\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\")\n",
    "logger = logging.getLogger(\"dashboard\")\n",
    "\n",
    "print(f\"PyTorch {torch.__version__} | Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Configuration\n",
    "\n",
    "Two configuration profiles are available. **Run ONLY one section:**\n",
    "- **Section 2a** — Synthetic data: minimal parameters for quick end-to-end testing\n",
    "- **Section 2b** — Real data: full production configuration\n",
    "\n",
    "Always run the **Global** cell (below) first, then choose ONE section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GLOBAL\n",
    "# ============================================================\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "USE_SYNTHETIC = True\n",
    "QUICK_MODE = False  # Set True for minimal config even with real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Synthetic Data (Quick Test)\n",
    "\n",
    "Run **only this cell** to configure the pipeline for a minimal end-to-end test on synthetic data. Skip Section 2b entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SYNTHETIC — Minimal config for end-to-end testing\n",
    "# Run ONLY this cell, then jump to Section 3\n",
    "# ============================================================\n",
    "\n",
    "if USE_SYNTHETIC:\n",
    "    QUICK_MODE = True  # Always True for synthetic data\n",
    "    DATA_PATH = \"\"\n",
    "    N_STOCKS = 10\n",
    "    N_YEARS = 6\n",
    "\n",
    "    # K=10 for speed; r_max relaxed because C_L floor (384) makes the CNN\n",
    "    # too large for small synthetic universes — acceptable for testing only.\n",
    "    config = PipelineConfig(\n",
    "        data=DataPipelineConfig(\n",
    "            n_stocks=N_STOCKS,\n",
    "            window_length=504,\n",
    "            n_features=2,\n",
    "        ),\n",
    "        vae=VAEArchitectureConfig(\n",
    "            K=10,\n",
    "            window_length=504,\n",
    "            n_features=2,\n",
    "            r_max=1e6,\n",
    "        ),\n",
    "        loss=LossConfig(mode=\"P\"),\n",
    "        training=TrainingConfig(\n",
    "            max_epochs=1,\n",
    "            batch_size=256,\n",
    "            learning_rate=1e-4,\n",
    "            patience=1,\n",
    "        ),\n",
    "        inference=InferenceConfig(),\n",
    "        risk_model=RiskModelConfig(),\n",
    "        portfolio=PortfolioConfig(n_starts=2),\n",
    "        walk_forward=WalkForwardConfig(\n",
    "            total_years=N_YEARS,\n",
    "            min_training_years=max(3, N_YEARS // 3),\n",
    "            holdout_years=max(1, N_YEARS // 5),\n",
    "        ),\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    HP_GRID = [{\"mode\": \"P\", \"learning_rate\": 1e-4, \"alpha\": 1.0}]\n",
    "\n",
    "    print(f\"[Synthetic mode] {N_STOCKS} stocks, {N_YEARS} years, K={config.vae.K}\")\n",
    "    print(f\"  max_epochs={config.training.max_epochs}, patience={config.training.patience}, HP_GRID=1 config, n_starts=2\")\n",
    "    print(f\"  r_max={config.vae.r_max:.0e} (relaxed for testing)\")\n",
    "    print(f\"  Walk-forward: {config.walk_forward.total_years}y total, \"\n",
    "        f\"{config.walk_forward.min_training_years}y min training, \"\n",
    "        f\"{config.walk_forward.holdout_years}y holdout\")\n",
    "    print(f\"  Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Real Data (Production)\n",
    "\n",
    "Run **all cells below** (through \"ASSEMBLE FULL CONFIG\") for full production configuration. Skip Section 2a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA SOURCE — Real data\n",
    "# ============================================================\n",
    "DATA_PATH = \"data/stock_data.csv\"  # <-- Set path to your stock data CSV\n",
    "\n",
    "# Synthetic parameters (unused when USE_SYNTHETIC=False)\n",
    "N_STOCKS = 50\n",
    "N_YEARS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA PIPELINE (MOD-001)\n",
    "# ============================================================\n",
    "data_cfg = DataPipelineConfig(\n",
    "    n_stocks=1000,               # universe cap (max stocks)\n",
    "    window_length=504,           # T: sliding window length (trading days)\n",
    "    n_features=2,                # F: features per timestep (return + realized vol)\n",
    "    vol_window=252,              # trailing vol lookback (days)\n",
    "    vix_lookback_percentile=80.0,# VIX percentile for crisis threshold\n",
    "    min_valid_fraction=0.80,     # minimum valid data fraction per stock\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VAE ARCHITECTURE (MOD-002)\n",
    "# ============================================================\n",
    "vae_cfg = VAEArchitectureConfig(\n",
    "    K=200,                       # latent capacity ceiling\n",
    "    sigma_sq_init=1.0,           # initial observation noise\n",
    "    sigma_sq_min=1e-4,           # lower clamp for sigma^2\n",
    "    sigma_sq_max=10.0,           # upper clamp for sigma^2\n",
    "    window_length=504,           # T (must match data_cfg)\n",
    "    n_features=2,                # F (must match data_cfg)\n",
    "    r_max=5.0,                   # max parameter/data ratio (relaxed for synthetic)\n",
    ")\n",
    "\n",
    "print(f\"Encoder depth L={vae_cfg.encoder_depth}, \"\n",
    "      f\"Final width C_L={vae_cfg.final_layer_width}, \"\n",
    "      f\"D={vae_cfg.D}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LOSS FUNCTION (MOD-004)\n",
    "# ============================================================\n",
    "loss_cfg = LossConfig(\n",
    "    mode=\"P\",                    # 'P' (primary), 'F' (fallback), 'A' (advanced)\n",
    "    gamma=3.0,                   # crisis overweighting factor\n",
    "    lambda_co_max=0.5,           # max co-movement loss weight\n",
    "    beta_fixed=1.0,              # fixed beta for Mode A\n",
    "    warmup_fraction=0.20,        # fraction of epochs for Mode F warmup\n",
    "    max_pairs=2048,              # max pairs for co-movement loss\n",
    "    delta_sync=21,               # max date gap for synchronization (days)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAINING (MOD-005)\n",
    "# ============================================================\n",
    "training_cfg = TrainingConfig(\n",
    "    max_epochs=100,              # maximum training epochs\n",
    "    batch_size=256,              # batch size\n",
    "    learning_rate=1e-4,          # initial learning rate (eta_0)\n",
    "    weight_decay=1e-5,           # Adam weight decay\n",
    "    adam_betas=(0.9, 0.999),     # Adam betas\n",
    "    adam_eps=1e-8,               # Adam epsilon\n",
    "    patience=10,                 # early stopping patience (epochs)\n",
    "    lr_patience=5,               # ReduceLROnPlateau patience\n",
    "    lr_factor=0.5,               # ReduceLROnPlateau factor\n",
    "    n_strata=15,                 # strata for synchronous batching\n",
    "    curriculum_phase1_frac=0.30, # fraction of epochs: sync+stratified batching\n",
    "    curriculum_phase2_frac=0.30, # fraction of epochs: + co-movement loss ramp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# INFERENCE (MOD-006)\n",
    "# ============================================================\n",
    "inference_cfg = InferenceConfig(\n",
    "    batch_size=512,              # inference batch size\n",
    "    au_threshold=0.01,           # KL threshold for active unit (nats)\n",
    "    r_min=2,                     # min observations-per-parameter for AU_max\n",
    "    aggregation_method=\"mean\",   # profile aggregation method\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RISK MODEL (MOD-007)\n",
    "# ============================================================\n",
    "risk_model_cfg = RiskModelConfig(\n",
    "    winsorize_lo=5.0,            # lower percentile for vol ratio winsorization\n",
    "    winsorize_hi=95.0,           # upper percentile\n",
    "    d_eps_floor=1e-6,            # floor for idiosyncratic variance\n",
    "    conditioning_threshold=1e6,  # condition number threshold for ridge fallback\n",
    "    ridge_scale=1e-6,            # ridge regularization scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PORTFOLIO OPTIMIZATION (MOD-008)\n",
    "# Constraints identical for VAE and all 6 benchmarks (INV-012)\n",
    "# ============================================================\n",
    "portfolio_cfg = PortfolioConfig(\n",
    "    lambda_risk=1.0,             # risk aversion\n",
    "    w_max=0.05,                  # max weight per stock (hard cap)\n",
    "    w_min=0.001,                 # min active weight (semi-continuous)\n",
    "    w_bar=0.03,                  # concentration penalty threshold\n",
    "    phi=25.0,                    # concentration penalty weight\n",
    "    kappa_1=0.1,                 # linear turnover penalty\n",
    "    kappa_2=7.5,                 # quadratic turnover penalty\n",
    "    delta_bar=0.01,              # turnover penalty threshold\n",
    "    tau_max=0.30,                # max one-way turnover (hard cap)\n",
    "    n_starts=5,                  # multi-start initializations\n",
    "    sca_max_iter=100,            # max SCA iterations\n",
    "    sca_tol=1e-8,               # SCA convergence tolerance\n",
    "    armijo_c=1e-4,               # Armijo sufficient decrease\n",
    "    armijo_rho=0.5,              # Armijo backtracking factor\n",
    "    armijo_max_iter=20,          # max Armijo backtracking steps\n",
    "    max_cardinality_elim=100,    # max cardinality elimination rounds\n",
    "    entropy_eps=1e-30,           # numerical stability for log()\n",
    "    alpha_grid=[0.0, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0],  # frontier alpha grid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# WALK-FORWARD VALIDATION (MOD-009)\n",
    "# ============================================================\n",
    "walk_forward_cfg = WalkForwardConfig(\n",
    "    total_years=30,              # total history length\n",
    "    min_training_years=10,       # minimum training window\n",
    "    oos_months=6,                # out-of-sample period (months)\n",
    "    embargo_days=21,             # embargo between train and OOS (trading days)\n",
    "    holdout_years=3,             # final holdout period\n",
    "    val_years=2,                 # nested validation for Phase A\n",
    "    score_lambda_pen=5.0,        # MDD penalty weight in composite score\n",
    "    score_lambda_est=2.0,        # estimation quality penalty weight\n",
    "    score_mdd_threshold=0.20,    # MDD threshold in composite score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# HP GRID for Phase A (set to None for default 18-config grid)\n",
    "# ============================================================\n",
    "HP_GRID = None  # None = default: 3 modes x 2 LRs x 3 alphas = 18 configs\n",
    "\n",
    "# Uncomment to define a custom grid:\n",
    "# HP_GRID = [\n",
    "#     {\"mode\": \"P\", \"learning_rate\": 5e-4, \"alpha\": 1.0},\n",
    "#     {\"mode\": \"F\", \"learning_rate\": 1e-3, \"alpha\": 0.5},\n",
    "#     {\"mode\": \"A\", \"learning_rate\": 1e-3, \"alpha\": 2.0},\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ASSEMBLE FULL CONFIG\n",
    "# ============================================================\n",
    "if not USE_SYNTHETIC:\n",
    "      config = PipelineConfig(\n",
    "            data=data_cfg,\n",
    "            vae=vae_cfg,\n",
    "            loss=loss_cfg,\n",
    "            training=training_cfg,\n",
    "            inference=inference_cfg,\n",
    "            risk_model=risk_model_cfg,\n",
    "            portfolio=portfolio_cfg,\n",
    "            walk_forward=walk_forward_cfg,\n",
    "            seed=SEED,\n",
    "      )\n",
    "\n",
    "      print(\"PipelineConfig assembled.\")\n",
    "      print(f\"  Walk-forward: {config.walk_forward.total_years}y total, \"\n",
    "            f\"{config.walk_forward.min_training_years}y min training, \"\n",
    "            f\"{config.walk_forward.holdout_years}y holdout\")\n",
    "      print(f\"  VAE: K={config.vae.K}, T={config.vae.window_length}, F={config.vae.n_features}\")\n",
    "      print(f\"  Training: {config.training.max_epochs} max epochs, \"\n",
    "            f\"bs={config.training.batch_size}, lr={config.training.learning_rate}\")\n",
    "      print(f\"  Loss mode: {config.loss.mode}, gamma={config.loss.gamma}\")\n",
    "      print(f\"  Capacity guard r_max: {config.vae.r_max}\")\n",
    "      print(f\"  Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# QUICK_MODE override for real data\n",
    "# When QUICK_MODE=True on real data, apply the same minimal\n",
    "# config as the synthetic path for fast end-to-end testing.\n",
    "# ============================================================\n",
    "if QUICK_MODE and not USE_SYNTHETIC:\n",
    "    config = replace(config,\n",
    "        vae=replace(config.vae, K=10, r_max=1e6),\n",
    "        training=replace(config.training, max_epochs=1, patience=1, batch_size=256, learning_rate=1e-4),\n",
    "        portfolio=replace(config.portfolio, n_starts=2),\n",
    "    )\n",
    "    HP_GRID = [{\"mode\": \"P\", \"learning_rate\": 1e-4, \"alpha\": 1.0}]\n",
    "    print(\"[QUICK MODE] Minimal config applied to real data\")\n",
    "    print(f\"  K={config.vae.K}, max_epochs={config.training.max_epochs}, \"\n",
    "          f\"patience={config.training.patience}, n_starts={config.portfolio.n_starts}\")\n",
    "    print(f\"  HP_GRID=1 config, r_max={config.vae.r_max:.0e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "\n",
    "if USE_SYNTHETIC:\n",
    "    start_year = 2000\n",
    "    end_year = start_year + N_YEARS\n",
    "    start_date = f\"{start_year}-01-03\"\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".csv\", delete=False) as f:\n",
    "        csv_path = f.name\n",
    "\n",
    "    generate_synthetic_csv(\n",
    "        csv_path,\n",
    "        n_stocks=N_STOCKS,\n",
    "        start_date=start_date,\n",
    "        end_date=f\"{end_year}-12-31\",\n",
    "        seed=SEED,\n",
    "    )\n",
    "    stock_data = load_stock_data(csv_path)\n",
    "    os.unlink(csv_path)\n",
    "    print(f\"Synthetic data: {N_STOCKS} stocks, {start_date} to {end_year}-12-31\")\n",
    "else:\n",
    "    stock_data = load_stock_data(DATA_PATH)\n",
    "    start_date = str(stock_data[\"date\"].min().date())\n",
    "    print(f\"Loaded data from {DATA_PATH}\")\n",
    "\n",
    "print(f\"Stock data shape: {stock_data.shape}\")\n",
    "print(f\"Date range: {stock_data['date'].min()} to {stock_data['date'].max()}\")\n",
    "print(f\"Unique stocks: {stock_data['permno'].nunique()}\")\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log-returns and trailing volatility\n",
    "returns = compute_log_returns(stock_data)\n",
    "trailing_vol = compute_trailing_volatility(returns, window=config.data.vol_window)\n",
    "\n",
    "print(f\"Returns: {returns.shape[0]} dates x {returns.shape[1]} stocks\")\n",
    "print(f\"Trailing vol: {trailing_vol.shape} (first {config.data.vol_window-1} rows NaN)\")\n",
    "print(f\"Returns date range: {returns.index[0]} to {returns.index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Run Pipeline\n",
    "\n",
    "Executes the full walk-forward validation: Phase A (HP selection) + Phase B (deployment) on each fold, then benchmarks, statistical tests, and report generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = FullPipeline(config)\n",
    "\n",
    "results = pipeline.run(\n",
    "    stock_data=stock_data,\n",
    "    returns=returns,\n",
    "    trailing_vol=trailing_vol,\n",
    "    skip_phase_a=USE_SYNTHETIC,\n",
    "    vix_data=None,\n",
    "    start_date=start_date,\n",
    "    hp_grid=HP_GRID,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "print(\"Pipeline complete.\")\n",
    "print(f\"Folds processed: {len(results['vae_results'])}\")\n",
    "print(f\"Benchmarks: {list(results['benchmark_results'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Results - Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text summary\n",
    "print(format_summary_table(results[\"report\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment recommendation\n",
    "deployment = results[\"report\"][\"deployment\"]\n",
    "print(f\"Scenario: {deployment['scenario']}\")\n",
    "print(f\"Recommendation: {deployment['recommendation']}\")\n",
    "print()\n",
    "print(\"Per-benchmark wins (VAE vs benchmark on primary metrics):\")\n",
    "for bench, info in deployment[\"per_benchmark\"].items():\n",
    "    print(f\"  {bench:20s}: {info['wins']}/{info['total']} metrics won\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE summary statistics\n",
    "vae_df = aggregate_fold_metrics(results[\"vae_results\"])\n",
    "vae_summary = summary_statistics(vae_df)\n",
    "print(\"VAE Summary Statistics:\")\n",
    "style_summary_table(vae_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark summary statistics\n",
    "for bench_name, bench_metrics in results[\"benchmark_results\"].items():\n",
    "    bench_df = aggregate_fold_metrics(bench_metrics)\n",
    "    bench_summary = summary_statistics(bench_df)\n",
    "    print(f\"\\n{bench_name} Summary:\")\n",
    "    display(style_summary_table(bench_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Results - Per-Fold Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE per-fold metrics\n",
    "print(\"VAE Per-Fold Metrics:\")\n",
    "style_fold_table(vae_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E* distribution\n",
    "e_star_summary = results[\"report\"][\"e_star_summary\"]\n",
    "print(f\"E* epochs: mean={e_star_summary['mean']:.1f}, \"\n",
    "      f\"std={e_star_summary['std']:.1f}, \"\n",
    "      f\"range=[{e_star_summary['min']}, {e_star_summary['max']}]\")\n",
    "\n",
    "plot_e_star_distribution(results[\"e_stars\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold metrics: VAE vs benchmarks\n",
    "plot_fold_metrics(results[\"vae_results\"], results[\"benchmark_results\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Results - Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise tests heatmap\n",
    "plot_pairwise_heatmap(results[\"report\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed pairwise test results\n",
    "tests = results[\"report\"][\"statistical_tests\"]\n",
    "print(f\"Total comparisons: {tests['n_tests']} (alpha={tests['alpha']})\")\n",
    "print()\n",
    "\n",
    "for bench_name, metrics in tests[\"pairwise\"].items():\n",
    "    print(f\"VAE vs {bench_name}:\")\n",
    "    for metric, result in metrics.items():\n",
    "        if result.get(\"skipped\", False):\n",
    "            print(f\"  {metric}: skipped ({result['reason']})\")\n",
    "            continue\n",
    "        sig = \" *\" if result.get(\"significant_corrected\", False) else \"\"\n",
    "        print(f\"  {metric}: delta={result['median_delta']:+.4f} \"\n",
    "              f\"[{result['ci_lower']:+.4f}, {result['ci_upper']:+.4f}] \"\n",
    "              f\"p={result.get('p_corrected', result['p_value']):.4f}{sig}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"results/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Fold metrics CSV\n",
    "vae_df.to_csv(os.path.join(OUTPUT_DIR, \"vae_fold_metrics.csv\"), index=False)\n",
    "\n",
    "for bench_name, bench_metrics in results[\"benchmark_results\"].items():\n",
    "    bench_df = aggregate_fold_metrics(bench_metrics)\n",
    "    bench_df.to_csv(os.path.join(OUTPUT_DIR, f\"{bench_name}_fold_metrics.csv\"), index=False)\n",
    "\n",
    "# Text report\n",
    "with open(os.path.join(OUTPUT_DIR, \"report.txt\"), \"w\") as f:\n",
    "    f.write(format_summary_table(results[\"report\"]))\n",
    "\n",
    "# JSON report\n",
    "with open(os.path.join(OUTPUT_DIR, \"report.json\"), \"w\") as f:\n",
    "    json.dump(serialize_for_json(results[\"report\"]), f, indent=2)\n",
    "\n",
    "# Config snapshot\n",
    "with open(os.path.join(OUTPUT_DIR, \"config.json\"), \"w\") as f:\n",
    "    json.dump(serialize_for_json(asdict(config)), f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {OUTPUT_DIR}\")\n",
    "print(f\"  vae_fold_metrics.csv\")\n",
    "print(f\"  <benchmark>_fold_metrics.csv (x{len(results['benchmark_results'])})\")\n",
    "print(f\"  report.txt\")\n",
    "print(f\"  report.json\")\n",
    "print(f\"  config.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Latent_risk_factor (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
