{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-00-md",
   "metadata": {},
   "source": [
    "# V2 Post-Mortem Diagnostic Experiments\n",
    "Scientific decomposition: diagnose before fixing. Cheapest experiments first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-01-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Project root: go up from notebooks/ to project root\n",
    "_NB_DIR = Path(os.path.abspath(\"\")).resolve()\n",
    "PROJECT_ROOT = (_NB_DIR / \"..\").resolve() if _NB_DIR.name == \"notebooks\" else _NB_DIR\n",
    "os.chdir(PROJECT_ROOT)\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.integration import diagnostic_experiments as dexp\n",
    "from src.integration.notebook_helpers import assemble_full_config, replay_oos_simulation\n",
    "from src.integration.pipeline_state import load_run_data\n",
    "from src.config import PipelineConfig\n",
    "from src.data_pipeline.data_loader import load_data_source\n",
    "from src.data_pipeline.returns import compute_log_returns\n",
    "from src.data_pipeline.features import compute_trailing_volatility\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\", force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-02-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: N=4500, K=75\n"
     ]
    }
   ],
   "source": [
    "# === EDIT THESE ===\n",
    "RUN_DIR = \"results/diagnostic_runs/2026-02-23_173155\"  # V1 or latest checkpoint\n",
    "# RUN_DIR_V2 = \"results/diagnostic_runs/2026-02-23_233353\"  # V2 for comparison\n",
    "\n",
    "# --- Data source (same as dashboard.ipynb) ---\n",
    "SEED = 42\n",
    "DATA_SOURCE = \"tiingo\"       # \"synthetic\", \"tiingo\", or \"csv\"\n",
    "DATA_PATH = \"data/stock_data.csv\"  # Only used when DATA_SOURCE = \"csv\"\n",
    "DATA_DIR = \"data/\"           # Directory for Tiingo downloaded data\n",
    "END_DATE = \"2025-12-31\"      # Latest date for data loading (None = today)\n",
    "\n",
    "# --- Universe & architecture (match your checkpoint or set new values) ---\n",
    "N_STOCKS = 4500              # Must match the checkpoint run (or set new for Tier 3)\n",
    "N_YEARS = 40\n",
    "K = 75                       # Must match the checkpoint run (or set new for Tier 3)\n",
    "\n",
    "# Phase 0 reverted config (clean baseline)\n",
    "config = assemble_full_config(\n",
    "    seed=SEED,\n",
    "    n_stocks=N_STOCKS,\n",
    "    K=K,\n",
    "    max_epochs=150,\n",
    "    # Phase 0 reverts:\n",
    "    lambda_co_max=0.1,\n",
    "    momentum_enabled=False,\n",
    "    momentum_weight=0.0,\n",
    "    phi=5.0,\n",
    "    sca_tol=1e-5,\n",
    ")\n",
    "print(f\"Config: N={config.data.n_stocks}, K={config.vae.K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-03-load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source: tiingo\n",
      "Stock data: 16752881 rows, 4500 stocks\n",
      "Date range: 1995-01-03 00:00:00 to 2025-12-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 15:49:55,027 WARNING Winsorizing 47 extreme returns (|r| > 2.0) caused by data errors\n",
      "/Users/mathis/1-Projects/Latent_risk_factor/src/data_pipeline/returns.py:113: UserWarning: returns has 52.4% NaN values, exceeds threshold 30.0%\n",
      "  warn_if_nan_fraction_exceeds(returns_df, 0.3, \"returns\")\n",
      "/Users/mathis/1-Projects/Latent_risk_factor/src/data_pipeline/returns.py:119: UserWarning: log_returns: 3101 returns exceed |50%| (0.018% of observations) - check for data errors\n",
      "  warn_if_price_discontinuity(returns_df, 0.5, \"log_returns\")\n",
      "2026-02-24 15:49:56,132 INFO Loaded run data from results/diagnostic_runs/2026-02-23_173155: ['run_dir', 'diagnostics', 'weights', 'stock_ids', 'run_config']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns: 7844 dates x 4500 stocks\n",
      "Trailing vol: (7844, 4500)\n",
      "\n",
      "Checkpoint: B_A (3303, 64), 3303 stocks, AU=64\n"
     ]
    }
   ],
   "source": [
    "# --- Load raw data (same as dashboard.ipynb Section 3) ---\n",
    "np.random.seed(SEED)\n",
    "stock_data, start_date = load_data_source(\n",
    "    source=DATA_SOURCE,\n",
    "    data_path=DATA_PATH if DATA_SOURCE == \"csv\" else \"\",\n",
    "    data_dir=DATA_DIR,\n",
    "    n_stocks=N_STOCKS,\n",
    "    n_years=N_YEARS,\n",
    "    seed=SEED,\n",
    "    end_date=END_DATE,\n",
    ")\n",
    "print(f\"Data source: {DATA_SOURCE}\")\n",
    "print(f\"Stock data: {stock_data.shape[0]} rows, {stock_data['permno'].nunique()} stocks\")\n",
    "print(f\"Date range: {stock_data['date'].min()} to {stock_data['date'].max()}\")\n",
    "\n",
    "# --- Compute returns and trailing volatility ---\n",
    "returns = compute_log_returns(stock_data)\n",
    "trailing_vol = compute_trailing_volatility(returns, window=config.data.vol_window)\n",
    "print(f\"Returns: {returns.shape[0]} dates x {returns.shape[1]} stocks\")\n",
    "print(f\"Trailing vol: {trailing_vol.shape}\")\n",
    "\n",
    "# --- Load checkpoint data ---\n",
    "exp_data = dexp.load_experiment_data(RUN_DIR)\n",
    "B_A = exp_data[\"B_A\"]\n",
    "stock_ids = exp_data[\"stock_ids\"]\n",
    "print(f\"\\nCheckpoint: B_A {B_A.shape}, {len(stock_ids)} stocks, AU={exp_data.get('AU', B_A.shape[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-04-split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [1995-01-03, 2019-10-03] (6275 days)\n",
      "OOS:   [2019-10-04, 2025-12-31] (1569 days)\n"
     ]
    }
   ],
   "source": [
    "# Train/OOS split\n",
    "all_dates = returns.index\n",
    "holdout_fraction = 0.2\n",
    "split_idx = int(len(all_dates) * (1 - holdout_fraction))\n",
    "train_start = str(all_dates[0].date())\n",
    "train_end = str(all_dates[split_idx - 1].date())\n",
    "oos_start = str(all_dates[split_idx].date())\n",
    "oos_end = str(all_dates[-1].date())\n",
    "returns_oos = returns.loc[oos_start:oos_end]\n",
    "print(f\"Train: [{train_start}, {train_end}] ({split_idx} days)\")\n",
    "print(f\"OOS:   [{oos_start}, {oos_end}] ({len(returns_oos)} days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-05-md-tier0",
   "metadata": {},
   "source": [
    "## Tier 0: Component Substitution (~5 min from checkpoint)\n",
    "Replace ONE component with a \"known-good\" version to identify the bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-06-tier0-run",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 15:50:17,635 INFO T0.0: Baseline (VAE + current config)\n",
      "2026-02-24 15:50:39,499 INFO Estimation rescaling: 6023/6275 dates processed, 252 skipped (no_stocks=0, no_vol_date=0, insufficient_vol=252)\n",
      "2026-02-24 15:52:14,658 WARNING   covShrinkage not installed, falling back to spiked shrinkage. Install with: pip install covShrinkage\n",
      "2026-02-24 15:52:14,692 INFO   Spiked shrinkage: gamma=0.013, sigma_sq=1.3555e-06, lambda_+=1.6887e-06, n_signal=28/65\n",
      "2026-02-24 15:52:15,274 INFO   D_eps James-Stein shrinkage (kurtosis-corrected): alpha=0.1571, d_bar=8.6818e-04, n_valid=2878, median_T=3368, median_kappa4=10.47\n",
      "2026-02-24 15:52:20,390 INFO Risk model built in 122.8s: AU=64, n_signal=28, cond=2983.5\n",
      "2026-02-24 15:52:21,315 INFO compute_adaptive_enb_target: target=8.12 (heuristic=14.0, ENB_spectrum=11.60, cap=8.12, n_signal=28)\n",
      "2026-02-24 15:52:21,316 INFO Frontier Phase 1: 5 coarse points (early_stop=True, target_enb=8.12)\n",
      "2026-02-24 15:52:21,316 INFO     Frontier alpha 1/5 (α=0.001, starts=3, iter=100)...\n",
      "2026-02-24 15:52:24,998 INFO Entropy gradient normalization: balance_ratio=0.1955, alpha=0.001 -> alpha_eff=0.000195453 (||risk_grad||=1.9545e+00, ||grad_H||=1.0000e+01)\n",
      "/Users/mathis/1-Projects/Latent_risk_factor/src/portfolio/sca_solver.py:1166: UserWarning: SCA final gradient norm 1.21e+00 > 1.0e-06\n",
      "  return sca_optimize(\n",
      "2026-02-24 15:54:00,760 INFO     Frontier alpha 2/5 (α=0.01, starts=3, iter=100)...\n",
      "2026-02-24 15:54:04,495 INFO Entropy gradient normalization: balance_ratio=0.1955, alpha=0.01 -> alpha_eff=0.00195453 (||risk_grad||=1.9545e+00, ||grad_H||=1.0000e+01)\n"
     ]
    }
   ],
   "source": [
    "tier0_results = dexp.run_all_tier0(\n",
    "    B_A=B_A, returns=returns, trailing_vol=trailing_vol,\n",
    "    stock_ids=stock_ids, config=config,\n",
    "    train_start=train_start, train_end=train_end,\n",
    "    returns_oos=returns_oos,\n",
    ")\n",
    "display(tier0_results.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-07-tier0-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart: Sharpe by experiment\n",
    "ax = axes[0]\n",
    "valid = tier0_results.dropna(subset=[\"sharpe\"])\n",
    "colors = [\"green\" if s > 0 else \"red\" for s in valid[\"sharpe\"]]\n",
    "ax.barh(valid[\"experiment\"], valid[\"sharpe\"], color=colors, alpha=0.7)\n",
    "ax.axvline(0, color=\"black\", linewidth=0.5)\n",
    "ax.set_xlabel(\"Sharpe Ratio (OOS)\")\n",
    "ax.set_title(\"Tier 0: Component Substitution\")\n",
    "\n",
    "# Decision annotations\n",
    "best_exp = valid.loc[valid[\"sharpe\"].idxmax()]\n",
    "ax.annotate(f\"Best: {best_exp['experiment']}\", xy=(best_exp[\"sharpe\"], best_exp[\"experiment\"]),\n",
    "            fontsize=8, fontweight=\"bold\")\n",
    "\n",
    "# n_active by experiment\n",
    "ax = axes[1]\n",
    "if \"n_active\" in valid.columns:\n",
    "    ax.barh(valid[\"experiment\"], valid[\"n_active\"], color=\"steelblue\", alpha=0.7)\n",
    "    ax.set_xlabel(\"Number of Active Positions\")\n",
    "    ax.set_title(\"Portfolio Cardinality\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-tier0-gate",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = tier0_results[tier0_results[\"experiment\"] == \"T0.0_baseline\"]\n",
    "pca_oracle = tier0_results[tier0_results[\"experiment\"] == \"T0.1_pca_oracle\"]\n",
    "\n",
    "baseline_sharpe = float(baseline[\"sharpe\"].iloc[0]) if len(baseline) > 0 else np.nan\n",
    "pca_sharpe = float(pca_oracle[\"sharpe\"].iloc[0]) if len(pca_oracle) > 0 else np.nan\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TIER 0 DECISION GATE\")\n",
    "print(\"=\" * 60)\n",
    "if not np.isnan(pca_sharpe) and pca_sharpe > baseline_sharpe + 0.1:\n",
    "    print(f\"  PCA oracle Sharpe ({pca_sharpe:.3f}) >> baseline ({baseline_sharpe:.3f})\")\n",
    "    print(\"  => FACTOR MODEL IS THE BOTTLENECK (Category B/E)\")\n",
    "    print(\"  => Proceed to Tier 1 to confirm, then Tier 3 for retraining\")\n",
    "elif not np.isnan(pca_sharpe) and pca_sharpe < -0.5:\n",
    "    print(f\"  PCA oracle Sharpe ({pca_sharpe:.3f}) still negative\")\n",
    "    print(\"  => PIPELINE IS ALSO BROKEN (Categories C/D)\")\n",
    "    print(\"  => Investigate risk model and solver\")\n",
    "else:\n",
    "    print(f\"  Baseline: {baseline_sharpe:.3f}, PCA oracle: {pca_sharpe:.3f}\")\n",
    "    print(\"  => Mixed signal -- proceed to Tier 1 and 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-09-md-tier1",
   "metadata": {},
   "source": [
    "## Tier 1: Factor Quality Profiling (~15 min)\n",
    "Is the VAE B_A better than random? Compute metrics independent of risk model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10-tier1-run",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier1_results = dexp.run_all_tier1(\n",
    "    B_A=B_A, returns=returns.loc[train_start:train_end],\n",
    "    stock_ids=stock_ids, n_random_trials=100, seed=42,\n",
    ")\n",
    "print(f\"CS R2:              {tier1_results['cs_r2']:.4f} ({tier1_results['cs_r2']*100:.2f}%)\")\n",
    "print(f\"Random baseline R2: {tier1_results['random_baseline_r2']:.4f} ({tier1_results['random_baseline_r2']*100:.2f}%)\")\n",
    "print(f\"Effective rank:     {tier1_results['effective_rank']:.1f}\")\n",
    "print(f\"Condition number:   {tier1_results['condition_number']:.1f}\")\n",
    "print(f\"Top-1 eigenvalue:   {tier1_results['top_1_eigenvalue_pct']*100:.1f}%\")\n",
    "print(f\"Factor autocorr:    {tier1_results['factor_autocorr_mean']:.3f}\")\n",
    "print(f\"\\nDECISION: {tier1_results['decision']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11-tier1-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# CS R2 distribution across dates\n",
    "ax = axes[0, 0]\n",
    "r2_by_date = tier1_results[\"cs_r2_by_date\"]\n",
    "ax.hist(r2_by_date, bins=50, alpha=0.7, label=f\"VAE (mean={tier1_results['cs_r2']:.3f})\")\n",
    "ax.axvline(tier1_results[\"random_baseline_r2\"], color=\"red\", linestyle=\"--\",\n",
    "           label=f\"Random baseline ({tier1_results['random_baseline_r2']:.3f})\")\n",
    "ax.set_xlabel(\"Cross-Sectional R2\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"CS R2 Distribution Across Dates\")\n",
    "ax.legend()\n",
    "\n",
    "# Singular value spectrum\n",
    "ax = axes[0, 1]\n",
    "sv = tier1_results[\"singular_values\"]\n",
    "ax.semilogy(range(1, len(sv)+1), sv, \"b.-\")\n",
    "ax.axhline(sv[0] * 0.01, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"1% of max\")\n",
    "ax.axvline(tier1_results[\"effective_rank\"], color=\"green\", linestyle=\"--\",\n",
    "           label=f\"Effective rank = {tier1_results['effective_rank']:.1f}\")\n",
    "ax.set_xlabel(\"Component Index\")\n",
    "ax.set_ylabel(\"Singular Value\")\n",
    "ax.set_title(\"B_A Singular Value Spectrum\")\n",
    "ax.legend()\n",
    "\n",
    "# Factor autocorrelation\n",
    "ax = axes[1, 0]\n",
    "autocorr = tier1_results[\"factor_autocorr\"]\n",
    "ax.bar(range(len(autocorr)), autocorr, alpha=0.7)\n",
    "ax.set_xlabel(\"Factor Index\")\n",
    "ax.set_ylabel(\"Autocorrelation (lag-1)\")\n",
    "ax.set_title(f\"Factor z_hat Autocorrelation (mean |rho|={tier1_results['factor_autocorr_mean']:.3f})\")\n",
    "ax.axhline(0, color=\"black\", linewidth=0.5)\n",
    "\n",
    "# Eigenvalue concentration\n",
    "ax = axes[1, 1]\n",
    "sv_sq = sv ** 2\n",
    "sv_cumsum = np.cumsum(sv_sq) / sv_sq.sum()\n",
    "ax.plot(range(1, len(sv_cumsum)+1), sv_cumsum, \"b.-\")\n",
    "ax.axhline(0.5, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"50%\")\n",
    "ax.axhline(0.9, color=\"orange\", linestyle=\"--\", alpha=0.5, label=\"90%\")\n",
    "ax.set_xlabel(\"Number of Components\")\n",
    "ax.set_ylabel(\"Cumulative Variance Explained\")\n",
    "ax.set_title(\"Eigenvalue Concentration\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12-md-tier2",
   "metadata": {},
   "source": [
    "## Tier 2: Parameter Sensitivity (~10 min total)\n",
    "Sweep ONE parameter at a time, all others at Phase 0 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13-tier2-run",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier2_results = dexp.run_all_tier2(\n",
    "    B_A=B_A, returns=returns, trailing_vol=trailing_vol,\n",
    "    stock_ids=stock_ids, config=config,\n",
    "    train_start=train_start, train_end=train_end,\n",
    "    returns_oos=returns_oos,\n",
    ")\n",
    "for name, df in tier2_results.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    display(df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14-tier2-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sweeps = len(tier2_results)\n",
    "fig, axes = plt.subplots(1, n_sweeps, figsize=(5*n_sweeps, 4))\n",
    "if n_sweeps == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, (name, df) in zip(axes, tier2_results.items()):\n",
    "    valid = df.dropna(subset=[\"sharpe\"])\n",
    "    if len(valid) == 0:\n",
    "        continue\n",
    "    x_labels = [str(v) for v in valid[\"param_value\"]]\n",
    "    ax.bar(x_labels, valid[\"sharpe\"], alpha=0.7)\n",
    "    ax.set_xlabel(name)\n",
    "    ax.set_ylabel(\"Sharpe\")\n",
    "    ax.set_title(f\"Sweep: {name}\")\n",
    "    ax.axhline(0, color=\"black\", linewidth=0.5)\n",
    "    # Mark best\n",
    "    best_idx = valid[\"sharpe\"].idxmax()\n",
    "    ax.bar(x_labels[list(valid.index).index(best_idx)],\n",
    "           valid.loc[best_idx, \"sharpe\"], color=\"green\", alpha=0.9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15-tier2-best",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TIER 2: BEST DOWNSTREAM CONFIG\")\n",
    "print(\"=\" * 60)\n",
    "for name, df in tier2_results.items():\n",
    "    valid = df.dropna(subset=[\"sharpe\"])\n",
    "    if len(valid) == 0:\n",
    "        print(f\"  {name}: ALL FAILED\")\n",
    "        continue\n",
    "    best = valid.loc[valid[\"sharpe\"].idxmax()]\n",
    "    print(f\"  {name}: best value = {best['param_value']}, Sharpe = {best['sharpe']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16-md-tier3",
   "metadata": {},
   "source": [
    "## Tier 3: Training Experiments (3-15h on Colab)\n",
    "Based on Tier 0-2 results, design targeted retraining experiments.\n",
    "Each tests ONE hypothesis. Run on Colab with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17-tier3-t31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T3.1: N=1000, K=50 (addresses biggest blind spot)\n",
    "# Apply best Tier 2 params from above\n",
    "config_t31 = assemble_full_config(\n",
    "    seed=42,\n",
    "    n_stocks=1000,\n",
    "    K=50,\n",
    "    max_epochs=150,\n",
    "    # Phase 0 reverts:\n",
    "    lambda_co_max=0.1,\n",
    "    momentum_enabled=False,\n",
    "    momentum_weight=0.0,\n",
    "    phi=5.0,\n",
    "    sca_tol=1e-5,\n",
    "    # Apply Tier 2 best params here:\n",
    "    # sigma_z_shrinkage=...,\n",
    "    # disable_vt=...,\n",
    ")\n",
    "print(f\"T3.1 Config: N={config_t31.data.n_stocks}, K={config_t31.vae.K}, \"\n",
    "      f\"epochs={config_t31.training.max_epochs}\")\n",
    "print(\"Run this config in dashboard.ipynb on Colab (expected ~2-3h)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18-tier3-factorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T3.2: N=4500, K=50 (isolates K effect)\n",
    "config_t32 = assemble_full_config(seed=42, n_stocks=4500, K=50, max_epochs=150,\n",
    "    lambda_co_max=0.1, momentum_enabled=False, phi=5.0, sca_tol=1e-5)\n",
    "\n",
    "# T3.3: N=1000, K=75 (isolates N effect)\n",
    "config_t33 = assemble_full_config(seed=42, n_stocks=1000, K=75, max_epochs=150,\n",
    "    lambda_co_max=0.1, momentum_enabled=False, phi=5.0, sca_tol=1e-5)\n",
    "\n",
    "print(\"Factorial design:\")\n",
    "print(\"         K=50      K=75\")\n",
    "print(f\"N=1000   T3.1      T3.3\")\n",
    "print(f\"N=4500   T3.2      (V1=existing)\")\n",
    "print(\"\\nOnly run T3.2/T3.3 if T3.1 results are ambiguous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19-tier3-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running T3.1 (and optionally T3.2, T3.3) on Colab:\n",
    "# T3_1_RUN_DIR = \"results/diagnostic_runs/YYYY-MM-DD_HHMMSS\"\n",
    "# t3_1_data = dexp.load_experiment_data(T3_1_RUN_DIR)\n",
    "# t3_1_tier1 = dexp.run_all_tier1(t3_1_data[\"B_A\"], returns, t3_1_data[\"stock_ids\"])\n",
    "# print(f\"T3.1 CS R2: {t3_1_tier1['cs_r2']*100:.2f}%, Decision: {t3_1_tier1['decision']}\")\n",
    "print(\"TODO: Fill in after running T3 experiments on Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20-md-decision",
   "metadata": {},
   "source": [
    "## Decision & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results into one table\n",
    "all_experiments = tier0_results.copy()\n",
    "# Add tier2 best configs if available\n",
    "for name, df in tier2_results.items():\n",
    "    valid = df.dropna(subset=[\"sharpe\"])\n",
    "    if len(valid) > 0:\n",
    "        best = valid.loc[valid[\"sharpe\"].idxmax()].to_dict()\n",
    "        best[\"experiment\"] = f\"T2_best_{name}\"\n",
    "        all_experiments = pd.concat([all_experiments, pd.DataFrame([best])], ignore_index=True)\n",
    "\n",
    "display(all_experiments.sort_values(\"sharpe\", ascending=False).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22-scorecard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic scorecard\n",
    "print(\"=\" * 70)\n",
    "print(\"DIAGNOSTIC SCORECARD\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Category':<20} {'Metric':<30} {'Value':<15} {'Status':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "cs_r2 = tier1_results['cs_r2']\n",
    "eff_rank = tier1_results['effective_rank']\n",
    "cond = tier1_results['condition_number']\n",
    "baseline_row = tier0_results[tier0_results[\"experiment\"] == \"T0.0_baseline\"].iloc[0]\n",
    "\n",
    "def status(val, good_lo, good_hi, crit_lo=None, crit_hi=None):\n",
    "    if good_lo <= val <= good_hi:\n",
    "        return \"OK\"\n",
    "    return \"CRITICAL\"\n",
    "\n",
    "print(f\"{'Factor Quality':<20} {'CS R2 (%)':<30} {cs_r2*100:<15.2f} {status(cs_r2, 0.15, 1.0):<10}\")\n",
    "print(f\"{'':<20} {'Effective rank':<30} {eff_rank:<15.1f} {status(eff_rank, 10, 1000):<10}\")\n",
    "print(f\"{'':<20} {'Random baseline R2':<30} {tier1_results['random_baseline_r2']*100:<15.2f} {'OK' if tier1_results['random_baseline_r2'] < cs_r2 else 'CRITICAL':<10}\")\n",
    "print(f\"{'Risk Model':<20} {'Condition number':<30} {cond:<15.1f} {status(cond, 0, 100):<10}\")\n",
    "print(f\"{'Portfolio':<20} {'Sharpe (OOS)':<30} {baseline_row['sharpe']:<15.3f} {status(baseline_row['sharpe'], 0.3, 10):<10}\")\n",
    "print(f\"{'':<20} {'Max drawdown':<30} {baseline_row.get('max_drawdown', 1.0):<15.3f} {status(baseline_row.get('max_drawdown', 1.0), 0, 0.5):<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"results/experiments\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save tier 0\n",
    "tier0_results.to_csv(output_dir / \"tier0_results.csv\", index=False)\n",
    "\n",
    "# Save tier 1\n",
    "tier1_export = {k: v for k, v in tier1_results.items()\n",
    "                if not isinstance(v, (np.ndarray, list)) or (isinstance(v, list) and len(v) < 100)}\n",
    "with open(output_dir / \"tier1_results.json\", \"w\") as f:\n",
    "    json.dump(tier1_export, f, indent=2, default=str)\n",
    "\n",
    "# Save tier 2\n",
    "for name, df in tier2_results.items():\n",
    "    df.to_csv(output_dir / f\"tier2_{name}.csv\", index=False)\n",
    "\n",
    "print(f\"Results exported to {output_dir}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Latent_risk_factor (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
