{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-00-md",
   "metadata": {},
   "source": [
    "# V2 Post-Mortem Diagnostic Experiments\n",
    "Scientific decomposition: diagnose before fixing. Cheapest experiments first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-01-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "from src.integration import diagnostic_experiments as dexp\n",
    "from src.integration.notebook_helpers import assemble_full_config, replay_oos_simulation\n",
    "from src.integration.pipeline_state import load_run_data\n",
    "from src.config import PipelineConfig\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THESE PATHS ===\n",
    "RUN_DIR = \"results/diagnostic_runs/YYYY-MM-DD_HHMMSS\"  # V1 or latest checkpoint\n",
    "# RUN_DIR_V2 = \"results/diagnostic_runs/2026-02-23_233353\"  # V2 for comparison\n",
    "\n",
    "# Phase 0 reverted config (clean baseline)\n",
    "config = assemble_full_config(\n",
    "    seed=42,\n",
    "    n_stocks=1000,  # Default, not 4500\n",
    "    K=50,           # Default, not 75\n",
    "    max_epochs=150,\n",
    "    # Phase 0 reverts:\n",
    "    lambda_co_max=0.1,\n",
    "    momentum_enabled=False,\n",
    "    momentum_weight=0.0,\n",
    "    phi=5.0,\n",
    "    sca_tol=1e-5,\n",
    ")\n",
    "print(f\"Config: N={config.data.n_stocks}, K={config.vae.K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03-load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint data\n",
    "exp_data = dexp.load_experiment_data(RUN_DIR)\n",
    "B_A = exp_data[\"B_A\"]\n",
    "stock_ids = exp_data[\"stock_ids\"]\n",
    "print(f\"Loaded: B_A {B_A.shape}, {len(stock_ids)} stocks, AU={exp_data.get('AU', B_A.shape[1])}\")\n",
    "\n",
    "# Load returns and trailing_vol (same as dashboard.ipynb cells 1-8)\n",
    "# NOTE: User must provide their own data loading here\n",
    "# returns = ...  # DataFrame (dates x permnos)\n",
    "# trailing_vol = ...  # DataFrame (dates x permnos)\n",
    "# stock_data = ...  # Raw stock data\n",
    "raise NotImplementedError(\"Load returns, trailing_vol, stock_data here (same as dashboard.ipynb)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-04-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/OOS split\n",
    "all_dates = returns.index\n",
    "holdout_fraction = 0.2\n",
    "split_idx = int(len(all_dates) * (1 - holdout_fraction))\n",
    "train_start = str(all_dates[0].date())\n",
    "train_end = str(all_dates[split_idx - 1].date())\n",
    "oos_start = str(all_dates[split_idx].date())\n",
    "oos_end = str(all_dates[-1].date())\n",
    "returns_oos = returns.loc[oos_start:oos_end]\n",
    "print(f\"Train: [{train_start}, {train_end}] ({split_idx} days)\")\n",
    "print(f\"OOS:   [{oos_start}, {oos_end}] ({len(returns_oos)} days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-05-md-tier0",
   "metadata": {},
   "source": [
    "## Tier 0: Component Substitution (~5 min from checkpoint)\n",
    "Replace ONE component with a \"known-good\" version to identify the bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-06-tier0-run",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier0_results = dexp.run_all_tier0(\n",
    "    B_A=B_A, returns=returns, trailing_vol=trailing_vol,\n",
    "    stock_ids=stock_ids, config=config,\n",
    "    train_start=train_start, train_end=train_end,\n",
    "    returns_oos=returns_oos,\n",
    ")\n",
    "display(tier0_results.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-07-tier0-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart: Sharpe by experiment\n",
    "ax = axes[0]\n",
    "valid = tier0_results.dropna(subset=[\"sharpe\"])\n",
    "colors = [\"green\" if s > 0 else \"red\" for s in valid[\"sharpe\"]]\n",
    "ax.barh(valid[\"experiment\"], valid[\"sharpe\"], color=colors, alpha=0.7)\n",
    "ax.axvline(0, color=\"black\", linewidth=0.5)\n",
    "ax.set_xlabel(\"Sharpe Ratio (OOS)\")\n",
    "ax.set_title(\"Tier 0: Component Substitution\")\n",
    "\n",
    "# Decision annotations\n",
    "best_exp = valid.loc[valid[\"sharpe\"].idxmax()]\n",
    "ax.annotate(f\"Best: {best_exp['experiment']}\", xy=(best_exp[\"sharpe\"], best_exp[\"experiment\"]),\n",
    "            fontsize=8, fontweight=\"bold\")\n",
    "\n",
    "# n_active by experiment\n",
    "ax = axes[1]\n",
    "if \"n_active\" in valid.columns:\n",
    "    ax.barh(valid[\"experiment\"], valid[\"n_active\"], color=\"steelblue\", alpha=0.7)\n",
    "    ax.set_xlabel(\"Number of Active Positions\")\n",
    "    ax.set_title(\"Portfolio Cardinality\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-tier0-gate",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = tier0_results[tier0_results[\"experiment\"] == \"T0.0_baseline\"]\n",
    "pca_oracle = tier0_results[tier0_results[\"experiment\"] == \"T0.1_pca_oracle\"]\n",
    "\n",
    "baseline_sharpe = float(baseline[\"sharpe\"].iloc[0]) if len(baseline) > 0 else np.nan\n",
    "pca_sharpe = float(pca_oracle[\"sharpe\"].iloc[0]) if len(pca_oracle) > 0 else np.nan\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TIER 0 DECISION GATE\")\n",
    "print(\"=\" * 60)\n",
    "if not np.isnan(pca_sharpe) and pca_sharpe > baseline_sharpe + 0.1:\n",
    "    print(f\"  PCA oracle Sharpe ({pca_sharpe:.3f}) >> baseline ({baseline_sharpe:.3f})\")\n",
    "    print(\"  => FACTOR MODEL IS THE BOTTLENECK (Category B/E)\")\n",
    "    print(\"  => Proceed to Tier 1 to confirm, then Tier 3 for retraining\")\n",
    "elif not np.isnan(pca_sharpe) and pca_sharpe < -0.5:\n",
    "    print(f\"  PCA oracle Sharpe ({pca_sharpe:.3f}) still negative\")\n",
    "    print(\"  => PIPELINE IS ALSO BROKEN (Categories C/D)\")\n",
    "    print(\"  => Investigate risk model and solver\")\n",
    "else:\n",
    "    print(f\"  Baseline: {baseline_sharpe:.3f}, PCA oracle: {pca_sharpe:.3f}\")\n",
    "    print(\"  => Mixed signal -- proceed to Tier 1 and 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-09-md-tier1",
   "metadata": {},
   "source": [
    "## Tier 1: Factor Quality Profiling (~15 min)\n",
    "Is the VAE B_A better than random? Compute metrics independent of risk model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10-tier1-run",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier1_results = dexp.run_all_tier1(\n",
    "    B_A=B_A, returns=returns.loc[train_start:train_end],\n",
    "    stock_ids=stock_ids, n_random_trials=100, seed=42,\n",
    ")\n",
    "print(f\"CS R2:              {tier1_results['cs_r2']:.4f} ({tier1_results['cs_r2']*100:.2f}%)\")\n",
    "print(f\"Random baseline R2: {tier1_results['random_baseline_r2']:.4f} ({tier1_results['random_baseline_r2']*100:.2f}%)\")\n",
    "print(f\"Effective rank:     {tier1_results['effective_rank']:.1f}\")\n",
    "print(f\"Condition number:   {tier1_results['condition_number']:.1f}\")\n",
    "print(f\"Top-1 eigenvalue:   {tier1_results['top_1_eigenvalue_pct']*100:.1f}%\")\n",
    "print(f\"Factor autocorr:    {tier1_results['factor_autocorr_mean']:.3f}\")\n",
    "print(f\"\\nDECISION: {tier1_results['decision']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11-tier1-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# CS R2 distribution across dates\n",
    "ax = axes[0, 0]\n",
    "r2_by_date = tier1_results[\"cs_r2_by_date\"]\n",
    "ax.hist(r2_by_date, bins=50, alpha=0.7, label=f\"VAE (mean={tier1_results['cs_r2']:.3f})\")\n",
    "ax.axvline(tier1_results[\"random_baseline_r2\"], color=\"red\", linestyle=\"--\",\n",
    "           label=f\"Random baseline ({tier1_results['random_baseline_r2']:.3f})\")\n",
    "ax.set_xlabel(\"Cross-Sectional R2\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"CS R2 Distribution Across Dates\")\n",
    "ax.legend()\n",
    "\n",
    "# Singular value spectrum\n",
    "ax = axes[0, 1]\n",
    "sv = tier1_results[\"singular_values\"]\n",
    "ax.semilogy(range(1, len(sv)+1), sv, \"b.-\")\n",
    "ax.axhline(sv[0] * 0.01, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"1% of max\")\n",
    "ax.axvline(tier1_results[\"effective_rank\"], color=\"green\", linestyle=\"--\",\n",
    "           label=f\"Effective rank = {tier1_results['effective_rank']:.1f}\")\n",
    "ax.set_xlabel(\"Component Index\")\n",
    "ax.set_ylabel(\"Singular Value\")\n",
    "ax.set_title(\"B_A Singular Value Spectrum\")\n",
    "ax.legend()\n",
    "\n",
    "# Factor autocorrelation\n",
    "ax = axes[1, 0]\n",
    "autocorr = tier1_results[\"factor_autocorr\"]\n",
    "ax.bar(range(len(autocorr)), autocorr, alpha=0.7)\n",
    "ax.set_xlabel(\"Factor Index\")\n",
    "ax.set_ylabel(\"Autocorrelation (lag-1)\")\n",
    "ax.set_title(f\"Factor z_hat Autocorrelation (mean |rho|={tier1_results['factor_autocorr_mean']:.3f})\")\n",
    "ax.axhline(0, color=\"black\", linewidth=0.5)\n",
    "\n",
    "# Eigenvalue concentration\n",
    "ax = axes[1, 1]\n",
    "sv_sq = sv ** 2\n",
    "sv_cumsum = np.cumsum(sv_sq) / sv_sq.sum()\n",
    "ax.plot(range(1, len(sv_cumsum)+1), sv_cumsum, \"b.-\")\n",
    "ax.axhline(0.5, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"50%\")\n",
    "ax.axhline(0.9, color=\"orange\", linestyle=\"--\", alpha=0.5, label=\"90%\")\n",
    "ax.set_xlabel(\"Number of Components\")\n",
    "ax.set_ylabel(\"Cumulative Variance Explained\")\n",
    "ax.set_title(\"Eigenvalue Concentration\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12-md-tier2",
   "metadata": {},
   "source": [
    "## Tier 2: Parameter Sensitivity (~10 min total)\n",
    "Sweep ONE parameter at a time, all others at Phase 0 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13-tier2-run",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier2_results = dexp.run_all_tier2(\n",
    "    B_A=B_A, returns=returns, trailing_vol=trailing_vol,\n",
    "    stock_ids=stock_ids, config=config,\n",
    "    train_start=train_start, train_end=train_end,\n",
    "    returns_oos=returns_oos,\n",
    ")\n",
    "for name, df in tier2_results.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    display(df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14-tier2-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sweeps = len(tier2_results)\n",
    "fig, axes = plt.subplots(1, n_sweeps, figsize=(5*n_sweeps, 4))\n",
    "if n_sweeps == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, (name, df) in zip(axes, tier2_results.items()):\n",
    "    valid = df.dropna(subset=[\"sharpe\"])\n",
    "    if len(valid) == 0:\n",
    "        continue\n",
    "    x_labels = [str(v) for v in valid[\"param_value\"]]\n",
    "    ax.bar(x_labels, valid[\"sharpe\"], alpha=0.7)\n",
    "    ax.set_xlabel(name)\n",
    "    ax.set_ylabel(\"Sharpe\")\n",
    "    ax.set_title(f\"Sweep: {name}\")\n",
    "    ax.axhline(0, color=\"black\", linewidth=0.5)\n",
    "    # Mark best\n",
    "    best_idx = valid[\"sharpe\"].idxmax()\n",
    "    ax.bar(x_labels[list(valid.index).index(best_idx)],\n",
    "           valid.loc[best_idx, \"sharpe\"], color=\"green\", alpha=0.9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15-tier2-best",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TIER 2: BEST DOWNSTREAM CONFIG\")\n",
    "print(\"=\" * 60)\n",
    "for name, df in tier2_results.items():\n",
    "    valid = df.dropna(subset=[\"sharpe\"])\n",
    "    if len(valid) == 0:\n",
    "        print(f\"  {name}: ALL FAILED\")\n",
    "        continue\n",
    "    best = valid.loc[valid[\"sharpe\"].idxmax()]\n",
    "    print(f\"  {name}: best value = {best['param_value']}, Sharpe = {best['sharpe']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16-md-tier3",
   "metadata": {},
   "source": [
    "## Tier 3: Training Experiments (3-15h on Colab)\n",
    "Based on Tier 0-2 results, design targeted retraining experiments.\n",
    "Each tests ONE hypothesis. Run on Colab with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17-tier3-t31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T3.1: N=1000, K=50 (addresses biggest blind spot)\n",
    "# Apply best Tier 2 params from above\n",
    "config_t31 = assemble_full_config(\n",
    "    seed=42,\n",
    "    n_stocks=1000,\n",
    "    K=50,\n",
    "    max_epochs=150,\n",
    "    # Phase 0 reverts:\n",
    "    lambda_co_max=0.1,\n",
    "    momentum_enabled=False,\n",
    "    momentum_weight=0.0,\n",
    "    phi=5.0,\n",
    "    sca_tol=1e-5,\n",
    "    # Apply Tier 2 best params here:\n",
    "    # sigma_z_shrinkage=...,\n",
    "    # disable_vt=...,\n",
    ")\n",
    "print(f\"T3.1 Config: N={config_t31.data.n_stocks}, K={config_t31.vae.K}, \"\n",
    "      f\"epochs={config_t31.training.max_epochs}\")\n",
    "print(\"Run this config in dashboard.ipynb on Colab (expected ~2-3h)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18-tier3-factorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T3.2: N=4500, K=50 (isolates K effect)\n",
    "config_t32 = assemble_full_config(seed=42, n_stocks=4500, K=50, max_epochs=150,\n",
    "    lambda_co_max=0.1, momentum_enabled=False, phi=5.0, sca_tol=1e-5)\n",
    "\n",
    "# T3.3: N=1000, K=75 (isolates N effect)\n",
    "config_t33 = assemble_full_config(seed=42, n_stocks=1000, K=75, max_epochs=150,\n",
    "    lambda_co_max=0.1, momentum_enabled=False, phi=5.0, sca_tol=1e-5)\n",
    "\n",
    "print(\"Factorial design:\")\n",
    "print(\"         K=50      K=75\")\n",
    "print(f\"N=1000   T3.1      T3.3\")\n",
    "print(f\"N=4500   T3.2      (V1=existing)\")\n",
    "print(\"\\nOnly run T3.2/T3.3 if T3.1 results are ambiguous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19-tier3-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running T3.1 (and optionally T3.2, T3.3) on Colab:\n",
    "# T3_1_RUN_DIR = \"results/diagnostic_runs/YYYY-MM-DD_HHMMSS\"\n",
    "# t3_1_data = dexp.load_experiment_data(T3_1_RUN_DIR)\n",
    "# t3_1_tier1 = dexp.run_all_tier1(t3_1_data[\"B_A\"], returns, t3_1_data[\"stock_ids\"])\n",
    "# print(f\"T3.1 CS R2: {t3_1_tier1['cs_r2']*100:.2f}%, Decision: {t3_1_tier1['decision']}\")\n",
    "print(\"TODO: Fill in after running T3 experiments on Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20-md-decision",
   "metadata": {},
   "source": [
    "## Decision & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results into one table\n",
    "all_experiments = tier0_results.copy()\n",
    "# Add tier2 best configs if available\n",
    "for name, df in tier2_results.items():\n",
    "    valid = df.dropna(subset=[\"sharpe\"])\n",
    "    if len(valid) > 0:\n",
    "        best = valid.loc[valid[\"sharpe\"].idxmax()].to_dict()\n",
    "        best[\"experiment\"] = f\"T2_best_{name}\"\n",
    "        all_experiments = pd.concat([all_experiments, pd.DataFrame([best])], ignore_index=True)\n",
    "\n",
    "display(all_experiments.sort_values(\"sharpe\", ascending=False).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22-scorecard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic scorecard\n",
    "print(\"=\" * 70)\n",
    "print(\"DIAGNOSTIC SCORECARD\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Category':<20} {'Metric':<30} {'Value':<15} {'Status':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "cs_r2 = tier1_results['cs_r2']\n",
    "eff_rank = tier1_results['effective_rank']\n",
    "cond = tier1_results['condition_number']\n",
    "baseline_row = tier0_results[tier0_results[\"experiment\"] == \"T0.0_baseline\"].iloc[0]\n",
    "\n",
    "def status(val, good_lo, good_hi, crit_lo=None, crit_hi=None):\n",
    "    if good_lo <= val <= good_hi:\n",
    "        return \"OK\"\n",
    "    return \"CRITICAL\"\n",
    "\n",
    "print(f\"{'Factor Quality':<20} {'CS R2 (%)':<30} {cs_r2*100:<15.2f} {status(cs_r2, 0.15, 1.0):<10}\")\n",
    "print(f\"{'':<20} {'Effective rank':<30} {eff_rank:<15.1f} {status(eff_rank, 10, 1000):<10}\")\n",
    "print(f\"{'':<20} {'Random baseline R2':<30} {tier1_results['random_baseline_r2']*100:<15.2f} {'OK' if tier1_results['random_baseline_r2'] < cs_r2 else 'CRITICAL':<10}\")\n",
    "print(f\"{'Risk Model':<20} {'Condition number':<30} {cond:<15.1f} {status(cond, 0, 100):<10}\")\n",
    "print(f\"{'Portfolio':<20} {'Sharpe (OOS)':<30} {baseline_row['sharpe']:<15.3f} {status(baseline_row['sharpe'], 0.3, 10):<10}\")\n",
    "print(f\"{'':<20} {'Max drawdown':<30} {baseline_row.get('max_drawdown', 1.0):<15.3f} {status(baseline_row.get('max_drawdown', 1.0), 0, 0.5):<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"results/experiments\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save tier 0\n",
    "tier0_results.to_csv(output_dir / \"tier0_results.csv\", index=False)\n",
    "\n",
    "# Save tier 1\n",
    "tier1_export = {k: v for k, v in tier1_results.items()\n",
    "                if not isinstance(v, (np.ndarray, list)) or (isinstance(v, list) and len(v) < 100)}\n",
    "with open(output_dir / \"tier1_results.json\", \"w\") as f:\n",
    "    json.dump(tier1_export, f, indent=2, default=str)\n",
    "\n",
    "# Save tier 2\n",
    "for name, df in tier2_results.items():\n",
    "    df.to_csv(output_dir / f\"tier2_{name}.csv\", index=False)\n",
    "\n",
    "print(f\"Results exported to {output_dir}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}