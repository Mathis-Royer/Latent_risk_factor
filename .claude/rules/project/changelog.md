# Changelog

> **Purpose:** Track recent significant changes. Update after each major modification.
> Keep ~10 entries. Merge similar entries rather than adding duplicates.

## Recent Changes

| # | Date | Modification |
|---|------|--------------|
| 1 | 2026-02-22 | **Phase 2 memory optimization (~3GB additional savings)** — 9 targeted optimizations completing the memory reduction work: (1) **data_loader.py** — `sort_values(..., ignore_index=True)` replaces `sort_values().reset_index()` (~640MB), `groupby().filter()` replaces `transform("count")` (~40MB), vectorized `generate_synthetic_csv()` builds arrays directly instead of 1.3M dict records (~800MB). (2) **windowing.py** — Pre-allocated metadata arrays (`meta_stock_ids`, `meta_start_idx`, `meta_end_idx`) replace list-of-dicts accumulation (~2.1GB for stride=1 inference), removed redundant `.copy()` and `.astype(float32)` calls (~40MB/stock transient). (3) **returns.py** — NumPy-based log-return computation avoids triple DataFrame temporaries (~186MB), vectorized `winsorize_returns()` replaces `apply(axis=1)` (~124MB). (4) **diagnostics.py** — Explicit `del returns_centered` after Bai-Ng IC2 call (~72MB). 4 files modified, 1016 tests pass, pyright 0 errors. Combined with Phase 1, total estimated peak reduction: ~43GB. |
| 2 | 2026-02-22 | **Memory explosion fix during VAE checkpoint saving (130GB+ RAM)** — Fixed critical memory explosion (~130GB RAM crash) during checkpoint saving after VAE training. Root causes: inference windows (stride=1 vs training stride=21 = 21× more data ~32GB), full fit_result history with per-dim KL arrays, and recursive JSON serialization without size guards. (1) **pipeline_state.py** — `_serialize_for_json()` now has size guards: arrays >100k elements return placeholder, lists >10k items return placeholder, DataFrames >10k cells return placeholder, max recursion depth=10. `save_state_bag_for_stage(VAE_TRAINED, ...)` now saves only fit_result summary scalars + compact training_curve (epoch, train_loss, val_elbo, AU, sigma_sq, learning_rate) — excludes large kl_per_dim and log_var_stats arrays. (2) **pipeline.py** — Added `import gc`. After aggregate_profiles(): `del infer_windows, infer_metadata, trajectories; gc.collect(); clear_device_cache(device)` (~32GB freed). After trainer.fit(): `trainer.cleanup(); del train_w, val_w, train_raw, metadata, train_metadata, train_strata; gc.collect()`. Before save_state_bag: clears train_returns, B_A_by_date, universe_snapshots from state_bag. (3) **early_stopping.py** — `restore_best()` now sets `self.best_state = None` after restoring weights (~20MB freed). (4) **trainer.py** — New `cleanup()` method: closes TensorBoard, clears torch.compile cache via `torch._dynamo.reset()`, clears early_stopping.best_state, zeros optimizer gradients, clears GradScaler, empties CUDA/MPS cache. (5) **11 new unit tests**: 7 for size guards/fit_result filtering in test_pipeline_state.py, 4 for trainer cleanup in test_training.py. 4 files modified, 75 tests pass, pyright 0 errors. Expected impact: RAM during checkpoint <5GB (vs 130GB+ crash). |
| 2 | 2026-02-21 | **Extended checkpointing for complete diagnostic recovery** — Implemented timestamped run folders with full state_bag persistence for dashboard sections 9-10: (1) **pipeline_state.py** (~200 lines added) — `DiagnosticRunManager` class (timestamped folder creation `results/diagnostic_runs/YYYY-MM-DD_HHMMSS/`, VAE checkpoint discovery, `save_run_config()` with git hash), `load_run_data()` helper for notebook loading. Extended `PipelineStateManager` with 8 methods: `save_json()`/`load_json()`, `save_stage_arrays()`/`load_stage_arrays()`, `save_scalars()`/`load_scalars()`, `save_state_bag_for_stage()`/`load_state_bag_for_stage()` — routes arrays→NPY, dicts→JSON, scalars→merged JSON. (2) **diagnostic_report.py** — `save_diagnostic_report()` now accepts `weights` and `stock_ids` params, saves to `arrays/portfolio/w_vae.npy` and `json/inferred_stock_ids.json`. (3) **run_diagnostic.py** — 3 new CLI args: `--run-dir PATH` (resume existing), `--vae-checkpoint PATH` (override), `--base-dir PATH` (new runs). Returns dict with `run_dir`, `weights`, `stock_ids`. (4) **pipeline.py** — Enhanced resume logic loads state_bag for all completed stages via `load_state_bag_for_stage()`. (5) **dashboard.ipynb** cell 63 — New config: `RUN_DIR`, `LOAD_EXISTING`, `VAE_CHECKPOINT_OVERRIDE`; conditional logic to load from existing folder or run diagnostic; exposes `ACTIVE_RUN_DIR`. (6) **27 new unit tests** in `test_pipeline_state.py`: `TestExtendedStateBagPersistence` (9), `TestDiagnosticRunManager` (11), `TestLoadRunData` (7). 5 files modified, 53 tests pass, pyright 0 errors. |
| 3 | 2026-02-21 | **OOS rebalancing performance optimization** — Implemented differentiated solver quality settings for scheduled vs exceptional rebalancing, reducing OOS simulation time by ~67%: (1) **config.py** — 5 new/modified parameters: `rebalancing_frequency_days` 21→63 (quarterly), `oos_n_starts_scheduled=2` (quick), `oos_n_starts_exceptional=5` (full quality), `oos_sca_max_iter_scheduled=50`, `oos_sca_max_iter_exceptional=100`. Added validation in `__post_init__`. (2) **oos_rebalancing.py** — `_execute_rebalancing()` now accepts `trigger` parameter to differentiate quality settings; passes `max_iter` to `multi_start_optimize`. Enhanced logging: INFO level with turnover breakdown (one-way/two-way/cumulative), rebalance counter, H before→after, n_active. Added `expected_scheduled` computation. (3) **pipeline.py** — `oos_constraint_params` dict now includes all 4 OOS quality settings. Impact: 74 scheduled rebalances → ~25, solver time per scheduled 2-3min → 30-60s, exceptional triggers retain full quality. 3 files modified, 60 tests pass, pyright 0 errors. |
| 4 | 2026-02-21 | **Incremental checkpointing + robust error handling** — Implemented full state management system to prevent losing hours of computation after crashes: (1) **NEW: `pipeline_state.py`** (~400 lines) — `PipelineStage` enum (10 stages: NOT_STARTED→COMPLETE), `StageStatus` enum (pending/success/failed/fallback), `StageInfo` dataclass (timestamps, error tracking), `PipelineState` dataclass (full state serializable to JSON), `PipelineStateManager` class (save/load state, save/load arrays as NPY, mark stages success/failed/fallback, get_resume_stage, benchmark status tracking). (2) **diagnostics.py** — Added `_safe_diagnostic()` wrapper that catches exceptions and returns `{available: False, error: "..."}` instead of crashing; wrapped all 11 diagnostic functions + health_checks + composite_scores. (3) **pipeline.py** — Added state manager initialization, resume logic (`resume: bool, force_stage: str | None` params), stage marking (start/success/failed), array checkpoints (B_A, kl_per_dim, Sigma_assets, w_vae), individual benchmark error isolation with fallback status tracking. (4) **run_diagnostic.py** — Added `--resume` and `--force-stage STAGE` CLI arguments passed through to pipeline. (5) **26 new unit tests** in `test_pipeline_state.py` covering all state management functionality + resume scenarios. 5 files modified/created, 947 tests pass, pyright 0 errors. |
| 5 | 2026-02-21 | **dropna() bug fix across 5 files** — Fixed "Found array with 0 sample(s)" errors caused by `.dropna()` dropping ALL rows when 1205 stocks had scattered NaN on different dates. (1) **Benchmarks (3 files)**: `min_variance.py`, `pca_factor_rp.py`, `pca_vol.py` — replaced `.dropna()` with ERC-style handling: filter stocks >50% NaN + `fillna(0.0)`. (2) **inverse_vol.py**: fallback volatility calculation now uses `fillna(0.0)` instead of `dropna()`. (3) **pipeline.py:2615**: OOS correlation metric now uses `fillna(0.0)` instead of `dropna(how="any")`. Audited all `.dropna()` calls — remaining usages are single-column Series (safe). 38 benchmark tests pass, pyright 0 new errors. |
| 6 | 2026-02-21 | **SVD non-convergence fix in factor quality diagnostics** — Fixed `LinAlgError: SVD did not converge` crash during `collect_diagnostics()`: (1) **bai_ng_ic2**: Added NaN/Inf validation before SVD — replaces non-finite values with 0, checks for degenerate (near-zero variance) matrices, wraps SVD in try/except returning k=1 fallback. (2) **factor_quality_diagnostics**: Added NaN handling for returns_centered — fills remaining NaN with column means before centering; wrapped `compute_factor_quality_dashboard()`, `bai_ng_ic2()`, and `onatski_eigenvalue_ratio()` calls in try/except with graceful fallbacks. (3) **2 new unit tests** in test_factor_quality.py: `test_handles_nan_values`, `test_handles_degenerate_matrix`. 2 files modified, 33 tests pass, pyright 0 errors. |
| 7 | 2026-02-21 | **Comprehensive Runtime Validation Audit** — Extended `src/validation.py` with 23 validation functions + added ~140 validation points across 27 files: (1) **validation.py extended** — 23 functions total: Phase 1 (15 functions): `assert_bounds()`, `assert_monotonic_dates()`, `assert_condition_number()`, `assert_date_alignment()`, `assert_stock_id_alignment()`, `assert_alignment_by_id()`, `assert_matrix_square()`, `assert_covariance_valid()`, `assert_positive_definite()`, `assert_returns_valid()`, `assert_weights_valid()`, `assert_tensor_shape()`, `assert_fold_consistency()`, `assert_no_lookahead()`, `warn_if_nan_fraction_exceeds()`. Phase 2 (8 functions): `assert_non_empty_dataframe()`, `assert_tensor_bounds()`, `warn_if_tensor_extreme()`, `assert_embargo_date_in_index()`, `assert_growth_finite()`, `warn_loss_explosion()`, `assert_active_units_valid()`, `assert_ann_vol_positive()`. Configurable via `VALIDATION_LEVEL` env var (strict/warn/off). (2) **Risk/Portfolio (8 files)** — covariance.py: PSD/eigenvalue/shrinkage checks; sca_solver.py: Cholesky finite, w_init sum, objective finite, w_new finite, H_final finite, final_weights valid, grad_norm warning; entropy.py: H >= 0, grad finite, idio_weight bounds, shape validation; factor_regression.py: z_hat finite, WLS weights valid; cardinality.py: weights sum, H reduction warning. (3) **Walk-Forward (8 files)** — folds.py: assert_no_lookahead; oos_rebalancing.py: w_aligned sum, embargo_end in index, growth guard, w_new sum; pipeline.py: fold schedule, data non-empty, B_A not None, alignments; metrics.py: B shape match, weights valid, ann_vol > 0. (4) **VAE/Training (5 files)** — model.py: log_var clamp, z/x_hat/mu finite; loss.py: L_recon not NaN, sigma_sq bounds, total_loss finite, Spearman bounds; trainer.py: batch > 0, loss explosion warning, AU <= K with validation function. (5) **Data Pipeline (6 files)** — data_loader.py: monotonic dates, price bounds, NaN warning; returns.py: column exists, finite returns, delisting bounds; windowing.py: z-score finite/bounds, tensor no NaN. (6) **149 unit tests** (41 new for Phase 2) in test_validation.py covering all 23 functions. 27 files modified, pyright 0 errors, 831 tests pass. |
| 8 | 2026-02-20 | **Dashboard Section 10: Decision Synthesis** — Added new Section 10 to `notebooks/dashboard.ipynb` (7 cells) integrating `decision_rules.py`, `action_specs.py`, and `diagnostic_schema.py` modules: (1) **10a. Root Cause Analysis** — calls `get_root_cause_analysis()` on composite scores, displays `format_diagnosis_summary()` with matched rules, patterns, causal chain, and priority actions. (2) **10b. Matched Decision Rules Table** — pandas DataFrame showing rule ID, diagnosis, confidence, severity, root causes for all triggered rules. (3) **10c. Causal Chain Visualization** — matplotlib flow diagram showing upstream causes → weakest component → downstream effects from `CAUSAL_GRAPH`. (4) **10d. Configuration Recommendations** — uses `get_executable_actions()` to map priority actions to concrete config changes with suggested values and rationale. (5) **10e. Validated JSON Export** — creates `decision_synthesis.json` with `validate_diagnostic_output()` schema validation, saves to results/diagnostic/. (6) **Quick Reference Card** — markdown table summarizing all 10 decision rules and action categories. Dashboard now complete for new users with full decision support. 1 file modified (dashboard.ipynb), 7 cells added, all imports verified. |
| 9 | 2026-02-20 | **4 new composite diagnostic scores** — Extended composite scoring system from 6 to 10 scores covering all pipeline phases: (1) **Training Convergence Score** (8% weight) — 4 components: timing (30% best_epoch_fraction optimal [0.3-0.85]), stability (25% val ELBO still decreasing penalty), LR scheduling (25% optimal 2-5 reductions), sigma bounds (20% penalty if hit). (2) **Active Unit Score** (7% weight) — 3 components: utilization (35% AU/K ratio [0.15-0.60] optimal), stability (30% au_final/au_max retention), spectrum (35% eff_dims/AU balance). (3) **Portfolio Diversification Score** (5% weight) — 4 components: entropy (40% H_norm_signal), ENB ratio (25% vs n_signal), position balance (25% eff_n/n_active), Gini (10%). (4) **Factor Stability Score** (5% weight) — 3 components: latent stability (50% Spearman rho ≥0.85), composition (30% pct_structural ≥50%), AU consistency (20% vs Bai-Ng IC2). Updated overall weights: covariance 20%, solver 15%, reconstruction 12%, vae_health 10%, factor_model 10%, constraint 8%. Updated docs/diagnostic.md with sections 2.6-2.9 and Quick Reference Card. 61 unit tests pass (27 new tests). 5 files modified. |
| 10 | 2026-02-19 | **Composite diagnostic scores + Executive Summary** — 6 functions in `composite_scores.py`: `compute_solver_health_score()`, `compute_constraint_pressure_score()`, `compute_covariance_quality_score()`, `compute_reconstruction_balance_score()`, `compute_overall_score()`, `compare_across_folds()`. Executive Summary in diagnostic_report.py. docs/diagnostic.md created. 34 unit tests. |


---

## Current State

- **Status**: Development — All 4 phases + tests + dashboard + performance optimizations + TensorBoard + diagnostic pipeline + **factor quality diagnostics** + **10 composite scores** + **Decision Synthesis (Section 10)** + **comprehensive runtime validation audit** + **extended checkpointing** + **OOS rebalancing optimization** + **memory explosion fix** + **training pipeline memory optimization** complete. 52 source files + 17 test files + 1 notebook (76 cells). SP500 priority download + penny stock/min history filters active.
- **Main features**: Full data pipeline, 1D-CNN VAE, 3-mode loss with co-movement curriculum, training loop with AMP + TensorBoard + curriculum batching + CUDA T4 optimizations (TF32, fused AdamW, gradient accumulation/checkpointing), inference + AU with AMP autocast, dual-rescaled factor risk model, portfolio optimization (SCA+Armijo, parametric CVXPY, Cholesky, parallel multi-starts, 4-strategy cardinality enforcement with MIQP pre-screening + two-stage decomposition), early training checkpoint, 6 benchmarks, walk-forward (34 folds) + direct training mode, statistical tests, reporting, **E2E diagnostic pipeline** (health checks, MD/JSON/CSV/PNG reports, quick/full profiles, **factor quality dashboard** with AU validation via Bai-Ng IC2 + Onatski + latent stability tracking, **10 composite scores** (0-100) covering all pipeline phases, **decision synthesis** with root cause analysis + causal chain + config recommendations), 3 CLI entry points, dashboard notebook, SP500-first download with data quality filters, **comprehensive validation utilities** (23 functions in src/validation.py, 149 unit tests), **winsorization + Bonferroni HP correction**, **extended checkpointing** (DiagnosticRunManager for timestamped folders, full state_bag persistence by stage, `--run-dir`/`--vae-checkpoint` CLI, dashboard LOAD_EXISTING mode), **OOS rebalancing optimization** (quarterly frequency, differentiated solver quality for scheduled/exceptional, ~67% time reduction), **memory optimizations** (float32 windowing, two-pass pre-allocation, pre-allocated metadata arrays, vectorized CSV generation, NumPy-based log-returns, lazy train_returns, ~43GB combined peak reduction)
- **Next**: Full Tiingo SP500 diagnostic re-run to verify memory optimizations on Colab.

---

## Update Protocol

After each significant modification:

1. Add new entry at position 1, shift others down
2. If similar entry exists, update it instead of adding
3. If > 10 entries, remove entry #10
4. Update "Current State" if project status changed
